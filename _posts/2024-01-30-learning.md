---
layout: post
title: Tips
date: 2024-01-19 16:00
description: what I learned from debugging
tags:
categories: learning
featured: false
---

# vim text editor

### Modes
normal mode (first screen I see after running the editor), insert mode (by hitting `i`), visual mode (by hitting `v`)

### Move cursor left right as a word
shift + left right arrow

### Display line number
`:set number`

###  Move without arrow keys
In normal mode
j : down  
k : up  
h : left  
l : right  

shift+left,right : move to start and end of a line

### Delete
In normal mode, use `x` (delete a character) or `dd` (delete a line)

### Undo / Redo
In normal mode, hit `u` for undo.  
`ctrl + r` for redo.

### Show line numbers
`:set number`

### Move to a line
`:2` : go to line number 2

### Copy and Paste
Go to visual mode by hitting `v`.  
Press `y` to copy, `d` to cut.  
Press `p` to paste

Notice. If `vim --version` says `-clipboard`, run `sudo apt-get install vim-gtk3 -y` to use mouse drag, cmd+c, cmd+v for copy and paste.
---
# Docker

## 

#ENV PATH /usr/local/envs/$CONDA_ENV_NAME/bin:$PATH
base                     /usr/local
dfm                      /usr/local/envs/dfm

vs

                         /usr/local
base                     /usr/local/envs/dfm

## Pytorch docker file
[link](https://gist.github.com/GzuPark/b89344cb93320e395ec357bc711a8799#file-pytorch-dockerfile)

---

## nvidia-docker is deprecated
To check whether nvidia containter toolkit is installed, use `nvidia-ctk --version`

---

# CUDA Programming

cuda설치해서 pytorch를 쓰는데 이 말은 pytorch써서 코드를 쓰면 그걸 gpu를 사용하게 해주는 cuda programming이 있다는 얘기. 즉 cuda programming 한다는말은 내가 쓴 코드가 gpu를 쓰게끔 한다는 말.

[link](https://www.linkedin.com/pulse/complete-introduction-gpu-programming-practical-examples-levinas/)  This link well explains about the relations between CUDA,PyCUDA, C++, etc. 
>"CUDA programming model allows software engineers to use a CUDA-enabled GPUs for general purpose processing in C/C++ and Fortran, with third party wrappers also available for Python, Java, R, and several other programming languages."

Here, thire party wrappers include PyCUDA. I.e., C++는 third party 없이 바로 가능하고, Python의 경우 PyCUDA를 써야된다?

>"Compute Unified Device Architecture (CUDA) is a parallel computing platform and application programming interface (API) created by Nvidia in 2006, that gives direct access to the GPU’s virtual instruction set for the execution of compute kernels."

API는 functions 등이 갖춰져있는 interface이고 kernel은 함수 정도로 이해.


# Pytorch

## pretty print
`from pprint import pprint`

`pprint`

---

## generator
[link](https://www.learnpytorch.io/01_pytorch_workflow/#4-making-predictions-with-a-trained-pytorch-model-inference)

`model_1.parameters()`

```
list(model_1.parameters())
```
```
for p in model_1.parameters():
  print(p)
```
[link2](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do-in-python)
```
def nextSquare():
    i = 1
 
    # An Infinite loop to generate squares
    while True:
        yield i*i
        i += 1
        if i > 10:
          break
        
for num in nextSquare():
  print(num)
  ```
# CCV

## Complaining about CUDA
Dont forget to load cuda
`module load cuda/x.x`  

---

## Choose a specific gpu
[link](https://docs.ccv.brown.edu/oscar/system-overview)
Use the names of gpu at the bottom of the page

For ex,

`interact -q gpu -f geforce3090 -g 1 -m 40g -n 4 -t 1:00:00`




# VScode

## diable auto activate virtual environment on vscode
[link](https://stackoverflow.com/questions/54802148/prevent-visual-studio-code-from-activating-the-python-virtual-environment)  
Check out the second answer.

`cmd + shift + p` -> json ssh setting (because I want to change vscode setting of sshed machine)  
-> type the following
```
{
    "terminal.integrated.defaultProfile.linux": "bash", # this is for default terminal
    "python.terminal.activateEnvironment": false,
}
```


# Linux

## nvidia cuda toolkit multiple versions

Shouldn't just install deb files. Also, follow specfic instructions installing .run local files.  
[link](https://towardsdatascience.com/managing-multiple-cuda-versions-on-a-single-machine-a-comprehensive-guide-97db1b22acdc)

This also covers this topic.  
[link](https://wiki.cs.umd.edu/gamma/view/Installing_multiple_versions_of_cuda_in_a_machine)

---

## Installing nvidia driver
[link](https://www.linuxcapable.com/install-nvidia-drivers-on-ubuntu-linux/)

(This process is called "Install NVIDIA Drivers with Ubuntu Repository using CLI")  
`sudo apt autoremove nvidia* --purge`  
`sudo apt update`  
`sudo apt upgrade` <- I don't know if this helped but I did it  
`ubuntu-drivers devices` <- I first installed 545 but had an issue. So did  
`sudo apt autoremove nvidia* --purge` 
`sudo apt install nvidia-driver-545`    
`sudo reboot`  

There's also a method "Install NVIDIA Drivers using graphics-drivers/ppa on Ubuntu"

Stick to using Ubuntu Repository if possible

## apt, apt-get, aptitude

Sometimes aptitude helps a lot. 

## Be cautious when updating nvidia driver and installing nvidia cuda toolkit

---



# SSH

## brown related ssh

There is a way to access Brown CS's file system on CCV  

`ssh brown` works because I have the following in Mac's `~/.ssh/config`  
`ssh jha38@ssh.cs.brown.edu` also works.  
```
Host brown
  HostName ssh.cs.brown.edu
  ForwardX11Trusted yes
  User jha38
```

`/data/jhtlab` locates at Brown CS's file system. After sshing into `brown`, do `cd ../../data/jhtlab/jha38`  
to find my folder.  

James said there's a way to access Brown CS's file system (`/data/jhtlab/jha38`) on CCV (`ssh oscar`)  



---

## ssh key pair
[link](https://walkingplow.tistory.com/72)  
I had an issue with sshing to hotcake / cake after regenerating ssh key pair.  
`ssh-copy-id -i ~/.ssh/id_rsa.pub jun@hotcake` this helped.  
This copy public ssh key to server's `authorized_keys` folder which is located under server's `~/.ssh`.  
After that, I can ssh into server just by `ssh hotcake` or `ssh cake`. For this, I guess I need to edit
configure file `config` under Mac's `~/.ssh`.  
For example,  
```
Host cake
  HostName cake
  User junsukha
```

# MLops

## basic usage of psycopg

[Basic module usage — Psycopg 2.9.9 documentation](https://www.psycopg.org/docs/usage.html#query-parameters)

---

## close and remove a container
```docker
docker stop "CONTAINTER ID"
docker rm "CONTAINER ID"
```

Use `docker ps -a` to see all containers

---

## host, container

```docker run -p 127.0.0.1:80:8080/tcp```\
This means to bind port 8080 of the container to TCP port 80 on 127.0.0.1 of the host machine.

---

## Any installation in a running container will be lost as soon as exiting the container
[dockerfile - Install package in running docker container - Stack Overflow](https://stackoverflow.com/questions/63027514/install-package-in-running-docker-container)

---

## add port tunneling between mac (local) and linux (remote) insidee a linux (remote), i.e. I ssh into linux (remote) from mac (local)

press `shift` and `~` and `c`. Hold `shift` while hitting `~` and `c`.\
`-L 8888:hotcake:8888` : connect mac's 8888 to hotcake's (server) 8888.\
[openssh - Add port forwarding to a running SSH session - Unix & Linux Stack Exchange](https://unix.stackexchange.com/questions/697825/add-port-forwarding-to-a-running-ssh-session)

---

## multiple port tunneling when ssh
[ssh -L forward multiple ports - Stack Overflow](https://stackoverflow.com/questions/29936948/ssh-l-forward-multiple-ports)

---

## how to find a docker host machine's ip address from inside a container?
`sudo ip addr show docker0` gives ip address of docker host machine (in my case 172.17.0.1)\
Also can identify ip address by `docker network inspect bridge`\
Both commands above are run in hotcake (the machine sshed into)\
To see an ip address of a container, run `ip addr show eth0` inside a container. 
* ex:  `root@e77f6a1b3740:/# ip addr show eth0`

[nginx - From inside of a Docker container, how do I connect to the localhost of the machine? - Stack Overflow](https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach)

---

## 03. Model Registry 2) Save Model to Registry
```python
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://172.17.0.1:9005" # when running in a container, should use host ip address instead of localhost?
os.environ["MLFLOW_TRACKING_URI"] = "http://172.17.0.1:5001"
```
Orignal version uses `"http://localhost:9005"` and `"http://localhost:5001"`. 9005 and 5001 are ports of Linux (remote machine) and are connected to 9091 and 9092 of mac (local) individually.

---

## How to debug inside a container with vscode
https://www.youtube.com/watch?v=w77D5KuJ7eE

I think there are two ways: 
1) access to a container with vscode from local (mac)
2) access to a conatiner with vscode from remote (linux); need to ssh from mac first

Method 1):
follow the video

Method 2):
* Install `Remote Development` extension (I thought, for this method, the extension should be installed in linux machine but accessing container also works when the extension is installed on mac)
* click a bottom left button and select `access to running container`
* choose a container (only currently running containers are visible)

---

## Pushing to a repo that I cloned from someone else's

https://stackoverflow.com/questions/18200248/cloning-a-repo-from-someone-elses-github-and-pushing-it-to-a-repo-on-my-github

1. Create a new repository at http://github.com (don't initialize README, .gitignore, license)
2. Clone a repo of someone else's to my local machine\
    git clone 


# DL

# c++

```c++
#include <iostream>
using namespace std;
 
class GfG {
public:
    static int x;
    GfG() {
        x++;
    }
    // static member function
    // static void printMsg() { cout << "Welcome to GfG!" << x; }
};

int GfG::x = 3; // just like static member function
 
// main function
int main()
{
    GfG obj1;
    cout << obj1.x << endl;
    obj1.x++;
    GfG obj2;
    cout << obj2.x << endl;

    // invoking a static member function
    // GfG::printMsg();
}
```

# Pytorch

## torch includes cuda toolkit
pytorch binary includes cuda toolkit. But it's not a bad idea to match local cuda toolkit and torch cuda toolkit. 

keywords: pytorch binary, build from source

--- 

## CUDA related issue while running a model

First thing to try is different versions; different python, pytorch, cuda versions.

---

## torch 2.0.x has issue with cuda

Don't use torch 2.0.x versions.

---

# ETC

---

